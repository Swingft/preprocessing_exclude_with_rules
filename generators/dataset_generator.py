"""
dataset_generator.py

ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

from config.settings import (
    INPUT_SWIFT_DIR, OUTPUT_JSONL, MAX_WORKERS, 
    REQUEST_DELAY, DEBUG
)
from handlers.claude_handler import ClaudeHandler
from analyzers.ast_analyzer import ASTAnalyzer
from analyzers.rule_filter import RuleFilter
from generators.prompt_builder import PromptBuilder


class DatasetGenerator:
    """ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, rules_yaml_path: Path):
        """
        Args:
            rules_yaml_path: YAML Rule íŒŒì¼ ê²½ë¡œ
        """
        self.claude_handler = ClaudeHandler()
        self.ast_analyzer = ASTAnalyzer(use_cache=True)
        self.rule_filter = RuleFilter(rules_yaml_path)
        self.prompt_builder = PromptBuilder()
    
    def process_single_file(self, swift_file: Path, file_index: int, total_files: int) -> Optional[Dict[str, str]]:
        """
        ë‹¨ì¼ Swift íŒŒì¼ ì²˜ë¦¬
        
        Args:
            swift_file: Swift íŒŒì¼ ê²½ë¡œ
            file_index: íŒŒì¼ ì¸ë±ìŠ¤
            total_files: ì „ì²´ íŒŒì¼ ìˆ˜
            
        Returns:
            {"instruction": "...", "input": "...", "output": "..."} ë˜ëŠ” None
        """
        try:
            print(f"[{file_index}/{total_files}] ì²˜ë¦¬ ì¤‘: {swift_file.name}")

            # 1. Swift ì½”ë“œ ë¡œë“œ
            swift_code = swift_file.read_text(encoding='utf-8')

            if not swift_code.strip():
                print(f"  âš ï¸  ë¹ˆ íŒŒì¼, ê±´ë„ˆëœ€")
                return None

            # 2. AST ì¶”ì¶œ
            print(f"  ğŸ“Š AST ì¶”ì¶œ ì¤‘...")
            ast_data = self.ast_analyzer.extract_ast(swift_file)

            # 3. Rule í•„í„°ë§
            if ast_data:
                print(f"  ğŸ” Rule í•„í„°ë§ ì¤‘...")
                filtered_rules = self.rule_filter.filter_rules_for_file(ast_data)
                rules_text = self.rule_filter.format_rules_for_prompt(filtered_rules)
                print(f"  âœ“ {len(filtered_rules)}ê°œ Rule ë§¤ì¹­")
            else:
                print(f"  âš ï¸  AST ì¶”ì¶œ ì‹¤íŒ¨, Rule ì—†ì´ ì§„í–‰")
                filtered_rules = []
                rules_text = "No rules available (AST extraction failed)"

            # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± (instruction + input ë¶„ë¦¬)
            instruction = """You are an expert Swift code auditor specializing in obfuscation safety analysis.

Analyze the provided Swift source code, AST (Abstract Syntax Tree), and exclusion rule examples to identify ALL identifiers that must be excluded from obfuscation.

**What to analyze:**
- Swift source code with complete implementation
- AST symbol information including attributes, inheritance, protocols, and modifiers
- Example exclusion rules (use as reference patterns, not exhaustive requirements)

**What to identify:**
- Framework delegate methods (UITableViewDelegate, UIApplicationDelegate, etc.)
- System lifecycle methods (viewDidLoad, viewWillAppear, applicationDidFinishLaunching, etc.)
- Protocol requirements and their implementations (Codable properties, Identifiable.id, etc.)
- @objc exposed symbols and Objective-C runtime dependencies
- IBOutlet, IBAction, and Interface Builder connections
- String-based lookups (KVC, KVO, NSCoding keys)
- Serialization properties (Codable, JSON keys)
- SwiftUI View body and environment properties
- Any identifiers that could break runtime behavior if renamed

**Critical instructions:**
1. The provided rules are EXAMPLES - use your Swift/iOS expertise to find additional patterns
2. Analyze ALL three inputs: source code, AST structure, and rule patterns
3. Return EVERY identifier that needs exclusion, even if not matching example rules
4. Consider runtime dependencies, framework contracts, and dynamic lookups

**Output format:**
Return a JSON object with this exact structure:
{"identifiers": ["identifier1", "identifier2", ...]}

Include ALL identifiers that must be excluded. Return empty array if none needed: {"identifiers": []}"""

            # input: Swift ì½”ë“œ + AST + Rules
            if ast_data:
                ast_json = json.dumps(ast_data, indent=2, ensure_ascii=False)
                input_text = f"""### Swift Source Code:
```swift
{swift_code}
```

### AST Symbol Information:
```json
{ast_json}
```

### Example Exclusion Rules (REFERENCE):
{rules_text}
"""
            else:
                input_text = f"""### Swift Source Code:
```swift
{swift_code}
```
"""

            # 5. ì „ì²´ í”„ë¡¬í”„íŠ¸ (Claude í˜¸ì¶œìš©)
            if ast_data:
                full_prompt = self.prompt_builder.build_prompt(swift_code, ast_data, rules_text)
            else:
                full_prompt = self.prompt_builder.build_simple_prompt(swift_code)

            if DEBUG:
                print(f"\n{'='*60}")
                print(f"PROMPT for {swift_file.name}:")
                print(full_prompt[:500] + "...")
                print(f"{'='*60}\n")

            # 6. Claude API í˜¸ì¶œ
            print(f"  ğŸ¤– Claude API í˜¸ì¶œ ì¤‘...")
            result = self.claude_handler.generate_with_retry(full_prompt)

            identifiers = result.get('identifiers', [])
            print(f"  âœ… ì™„ë£Œ: {len(identifiers)}ê°œ ì‹ë³„ì ì¶”ì¶œ")

            if DEBUG and identifiers:
                print(f"     ì‹ë³„ì: {identifiers[:10]}")

            # 7. Alpaca í˜•ì‹ ë°ì´í„°ì…‹ í•­ëª© ìƒì„±
            dataset_entry = {
                "instruction": instruction,
                "input": input_text,
                "output": json.dumps(result, ensure_ascii=False)
            }

            return dataset_entry

        except Exception as e:
            print(f"  âŒ ì—ëŸ¬: {e}")
            return None

    def generate_dataset(self, limit: Optional[int] = None, use_parallel: bool = True) -> int:
        """
        ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±

        Args:
            limit: ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            use_parallel: ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€

        Returns:
            ì„±ê³µí•œ íŒŒì¼ ìˆ˜
        """
        # Swift íŒŒì¼ ëª©ë¡ (ì¬ê·€ ê²€ìƒ‰)
        swift_files = sorted(INPUT_SWIFT_DIR.rglob("*.swift"))

        if not swift_files:
            print(f"âŒ Swift íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {INPUT_SWIFT_DIR}")
            return 0

        if limit:
            swift_files = swift_files[:limit]

        total_files = len(swift_files)

        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ í™•ì¸
        processed_files = set()
        if OUTPUT_JSONL.exists():
            print(f"ğŸ“‹ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {OUTPUT_JSONL}")
            try:
                with open(OUTPUT_JSONL, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            entry = json.loads(line)
                            # inputì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                            # ë˜ëŠ” ì¹´ìš´íŠ¸ë§Œ ì„¸ê¸°
                            processed_files.add(len(processed_files))
                print(f"âœ“ ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©: {len(processed_files)}ê°œ")
            except:
                print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨, ìƒˆë¡œ ì‹œì‘")
                processed_files = set()

        print(f"\n{'='*60}")
        print(f"ğŸ“¦ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
        print(f"{'='*60}")
        print(f"ì´ íŒŒì¼ ìˆ˜: {total_files}")
        print(f"ì´ë¯¸ ì²˜ë¦¬ë¨: {len(processed_files)}ê°œ")
        print(f"ì²˜ë¦¬ ëŒ€ìƒ: {total_files - len(processed_files)}ê°œ")
        print(f"ë³‘ë ¬ ì²˜ë¦¬: {use_parallel} (ì›Œì»¤: {MAX_WORKERS if use_parallel else 1})")
        print(f"ì¶œë ¥ íŒŒì¼: {OUTPUT_JSONL}")
        print(f"{'='*60}\n")

        start_time = time.time()
        success_count = len(processed_files)  # ê¸°ì¡´ ì²˜ë¦¬ ê°œìˆ˜ë¶€í„° ì‹œì‘

        # JSONL íŒŒì¼ ì—´ê¸° (append ëª¨ë“œë¡œ ì´ì–´ì“°ê¸°)
        mode = 'a' if OUTPUT_JSONL.exists() else 'w'
        with open(OUTPUT_JSONL, mode, encoding='utf-8') as f:

            if use_parallel and total_files > 1:
                # ë³‘ë ¬ ì²˜ë¦¬
                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                    futures = {}

                    for i, swift_file in enumerate(swift_files, 1):
                        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸° (ê°„ë‹¨í•œ ì¸ë±ìŠ¤ ê¸°ë°˜)
                        if i - 1 < len(processed_files):
                            print(f"[{i}/{total_files}] â­ï¸  ê±´ë„ˆëœ€: {swift_file.name} (ì´ë¯¸ ì²˜ë¦¬ë¨)")
                            continue

                        future = executor.submit(
                            self.process_single_file,
                            swift_file,
                            i,
                            total_files
                        )
                        futures[future] = swift_file

                        # API ê³¼ë¶€í•˜ ë°©ì§€
                        time.sleep(REQUEST_DELAY)

                    # ê²°ê³¼ ìˆ˜ì§‘
                    for future in as_completed(futures):
                        swift_file = futures[future]

                        try:
                            result = future.result()

                            if result:
                                # JSONL ì €ì¥
                                f.write(json.dumps(result, ensure_ascii=False) + '\n')
                                f.flush()
                                success_count += 1

                        except Exception as e:
                            print(f"âŒ {swift_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

            else:
                # ìˆœì°¨ ì²˜ë¦¬
                for i, swift_file in enumerate(swift_files, 1):
                    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                    if i - 1 < len(processed_files):
                        print(f"[{i}/{total_files}] â­ï¸  ê±´ë„ˆëœ€: {swift_file.name} (ì´ë¯¸ ì²˜ë¦¬ë¨)")
                        continue

                    result = self.process_single_file(swift_file, i, total_files)

                    if result:
                        f.write(json.dumps(result, ensure_ascii=False) + '\n')
                        f.flush()
                        success_count += 1

                    # ë”œë ˆì´
                    if i < total_files:
                        time.sleep(REQUEST_DELAY)

        # ê²°ê³¼ ì¶œë ¥
        elapsed_time = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {total_files - success_count}ê°œ")
        print(f"ğŸ“Š ì„±ê³µë¥ : {success_count / total_files * 100:.1f}%")
        print(f"ğŸ“ ì¶œë ¥: {OUTPUT_JSONL}")
        print(f"{'='*60}\n")

        return success_count